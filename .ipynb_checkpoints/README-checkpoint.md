# ReverseKnowledgeDistillation
This repository contains official implementation of our code for the paper "Reverse Knowledge Distillation : Training a larger model with a smaller one" accepted for WACV 2024
